{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose is lowering the memory\n",
    "\n",
    "\n",
    "#https://github.com/jonas-pettersson/fast-ai/blob/master/Exploration%20and%20Prediction%20for%20Structured%20Data.ipynb\n",
    "#https://forums.fast.ai/t/unofficial-lesson-3-classnotes/7567\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hafiz/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "df_raw = feather.read_dataframe('/tmp/raw')\n",
    "print('import complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to reduce memory\n",
    "\n",
    "types = {'id': 'int64',\n",
    "        'item_nbr': 'int32',\n",
    "        'store_nbr': 'int8',\n",
    "        'unit_sales': 'float32',\n",
    "        'onpromotion': 'object'}\n",
    "\n",
    "#objects are create general purpose python data type\n",
    "\n",
    "#onpromotion iis boolean having missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_all = pd.read_csv(f'{PATH}train_basic.csv', parse_dates=['date'], dtype=types, \n",
    "                     infer_datetime_format=True)#, skiprows=range(1,100000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#onpromotion iis boolean having missing value so filled the missing\n",
    "#value = false EDA says missing =false is not approperiate\n",
    "df_all.onpromotion.fillna(False, inplace=True)\n",
    "#above you can see the datatype is object for onpromotion by default \n",
    "#string so we replace it with boolean\n",
    "df_all.onpromotion = df_all.onpromotion.map({'False': False, 'True': True})\n",
    "#finally changed the data type\n",
    "df_all.onpromotion = df_all.onpromotion.astype(bool)\n",
    "\n",
    "#by doing this 123 million rows take 2.5 gigabytes of datatype\n",
    "\n",
    "\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "\n",
    "#look you can save it in feather format under 5 seconds\n",
    "%time df_all.to_feather('tmp/raw_groceries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the time is 23.1s\n",
    "\n",
    "%time df_all.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first important thing is look at dates \n",
    "\n",
    "#date is important among the other stuff\n",
    "\n",
    "#anything in the world changes then you need to know\n",
    "#how your predictive accuracy changes as well\n",
    "\n",
    "#make sure your date dont overlap\n",
    "#here we have date 2013 to 2017\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now look at test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'{PATH}test.csv', parse_dates = ['date'],\n",
    "                      dtype=types, infer_datetime_format=True)\n",
    "df_test.onpromotion.fillna(False, inplace=True)\n",
    "df_test.onpromotion = df_test.onpromotion.map({'False': False, \n",
    "                                               'True': True})\n",
    "df_test.onpromotion = df_test.onpromotion.astype(bool)\n",
    "df_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here you can see in test data dates are 1 day later\n",
    "#to summarize the discussion you can see in training set\n",
    "#you have 3 year of data and in testing set you are predicting\n",
    "#next 3 weeks of data\n",
    "\n",
    "# what if you have small dataset then you should not do random \n",
    "#sampling just sample the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ques\n",
    "\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In competetion there is some negative sales\n",
    "# which means return they consider that we should consider \n",
    "#them zero\n",
    "#so the sales falls between zero and no perticular maximum9none\n",
    "\n",
    "#clip that and take log +1 rms\n",
    "\n",
    "df_all.unit_sales = np.log1p(np.clip(df_all.unit_sales, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time add_datepart(df_all, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a, n): return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = len(df_test)\n",
    "n_trn = len(df_all) - n_valid\n",
    "train, valid = split_vals(df_all, n_trn)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of the dataset is already numeric\n",
    "\n",
    "# train_cats(raw_train)\n",
    "# apply_cats(raw_valid, raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trn, y, nas = proc_df(train, 'unit_sales')\n",
    "val, y_val, nas = proc_df(valid, 'unit_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x, y): return math.sqrt(((x-y)**2).mean())\n",
    "`\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(x), y), rmse(m.predict(val), y_val),\n",
    "          m.score(x, y), m.score(val, y_val)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rf_samples(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time x = np.array(trn, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set n_jobs=-1 to use all CPU cores available\n",
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=100, n_jobs=-1) \n",
    "%time m.fit(x, y)\n",
    "#%prun m.fit(x, y) to check which line of code take how much time\n",
    "#why did not do oob score then it will take other million\n",
    "#rows to calculate which means forever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average cell sale in month of august,\n",
    "\n",
    "#how about performance of new model with new column on x-axis and\n",
    "#y-axis previous model\n",
    "\n",
    "#tackling this problem with creating new columns average sale, inference\n",
    "#column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rossmann store sales Blog kaggle to see that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#significance of validation set\n",
    "\n",
    "#47:28 kaggle laderboard score and vidation test score identical \n",
    "#see plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
